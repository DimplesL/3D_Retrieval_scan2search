As the amount of 3D data is increasing on the Internet, many kinds of 3D retrieval engines are developed. Basic keyword-based retrieval techniques are not always effective, therefore content-based retrieval engines appear. This project focuses on developing a shape-based retrieval system, which provide a "scan to search" solution. The user can scan a object and reconstruct its 3D model with an app "123D", and use the scanned 3D point cloud as an input to retrieve models with similar shape. 

Firstly, the scanned data needs to be pre-processed. Scanned noise will be reduced via a 3D bilateral filter. Then the 3D data will be rasterized to a voxel grid and normalized to a certain scale. Thus high frequency noise is avoided while the shape information is mostly kept. Secondly, the shape information is described by applying a spherical harmonics decomposition of 3D data, as well as computing a distances distribution. These describtors are rotation invariant and noise insensitive. By computing the Euclidean distance between two descriptors, the similarity of two 3D models can be acquired, and thus the system can retrieve models with similar shapes. Also, this system provides six candidate models with high similarities, so that to avoid mis-matching. 

To verify and test the system, several test cases are carried out. Rotational invariance are first tested, to verify that the rotation invariant descriptors are computed correctly. Noise resistant test is then carried out. The last test is to input a scanned 3D model, and retrive similar models in the database. The results shows candidates with similar shapes. Thus this system is completed.